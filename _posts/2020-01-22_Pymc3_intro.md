
# Dive into Probabilistic Programming in Python with PyMC3

One of my computational learning goals for 2019 was learning more about probabilistic machine learning. This articles provides an introduction on how to estimate solve a linear regression problem — Bayesian style with Markov Chain Monte Carlo simulations!

<em>Alert! If you have a basic machine learning background then I highly recommend reading Prof.Zoubin Ghahramani’s (Director of Uber AI, University of Cambridge) excellent and persuasive review on Probabilistic Machine Learning (Nature 2015), and his NIPS talk on said topic. I became desensitised by his presentations and felt bold enough to finally dive into probabilistic machine learning.</em>
<h3>Why Probabilistic Programming?</h3>
A model describes data that could be observed from a system, given a set of assumptions. Uncertainty plays a fundamental role in modelling role since it is inherent in all data. Sources of uncertainty includes:

noise,
choosing the appropriate model given the data, and
the parameter values that define model which are used to predict new data.
A well-defined model is one that forecasts or make predictions about unobserved data having been trained on observed data. Probability theory is the mathematical framework for modelling all forms of uncertainty. Bayesian probabilistic models are used to quantify uncertainty, and incorporate this information during forecasting.
<h3>Components of Bayesian Probabilistic Models</h3>
Key Point: Instead of the conventional approach of learning single point estimates for the weights that define a model, Bayesian models learn the distribution underlying the weights.
The following are 3 the fundamental components to probabilistic models:
<ul>
	<li><strong>Model Prior</strong>: this is the probability distribution, p(Θ) that represents our beliefs or domain knowledge about the unobserved data before taking into consideration the observed data.</li>
	<li><strong>Model Posterior</strong>: This is the probability distribution, p(Θ|X) that represents the updated version of the prior after learning from the data (X).</li>
	<li><strong>Likelihood</strong>: this is the probability distribution, p(X|Θ) that represents the observed data. i.e. how we think the data is distributed.</li>
</ul>
[caption id="attachment_55" align="alignnone" width="663"]<img class="alignnone size-full wp-image-55" src="https://rhondenewint.files.wordpress.com/2019/01/bayes_theorem.png" alt="bayes_theorem" width="663" height="175" /> Bayes' Theorem[/caption]
<p id="37b8" class="graf graf--p graf-after--figure">Therefore, probabilistic models allows us to update our beliefs in light of the data. Supervised learning in Bayesian looks like this <strong class="markup--strong markup--p-strong">p(y|X,Θ)</strong>, i.e., having seen X what can we say now about y?</p>

<h4 id="9ee5" class="graf graf--h4 graf-after--p">PyMC3</h4>
<p id="d50b" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">PyMc3 is python package for probabilistic modelling. These examples are mostly from the originally published PyMC3 </em><a class="markup--anchor markup--p-anchor" href="https://peerj.com/articles/cs-55/" target="_blank" rel="noopener nofollow" data-href="https://peerj.com/articles/cs-55/"><em class="markup--em markup--p-em">article</em></a><em class="markup--em markup--p-em"> from Peer Journal Computer Science.</em></p>
<p id="78f8" class="graf graf--p graf-after--p">The full implementation of my code with detailed walk-through can be found on my github <a class="markup--anchor markup--p-anchor" href="https://github.com/rhondene/Probablistic_Bayesian_Models/blob/master/Intro_to_MCMC_PyMC3.ipynb" target="_blank" rel="noopener nofollow" data-href="https://github.com/rhondene/Probablistic_Bayesian_Models/blob/master/Intro_to_MCMC_PyMC3.ipynb">here</a>.</p>

<h3 id="f3de" class="graf graf--h3 graf-after--p">Why we use Markov Chain Monte Carlo</h3>
<p id="cf59" class="graf graf--p graf-after--h3">Simulation based algorithms are necessary because for many real-world high-dimensional data we cannot analytically compute the posterior distribution according to Bayes’ Theorem. Simulation based sampling methods like <strong class="markup--strong markup--p-strong">Markov Chain Monte Carlo</strong> algorithms that can generate samples from the posterior distribution. There are several different implementations of the MCMC algorithm, for example, Hamiltonian, Metropolis, NUTS, Slice etc.</p>
<p id="1b0e" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Metropolis-Hastings MCMC </strong>is the most basic flavour of MCMC. MH-MCMC samples from a generic probability distribution target distribution by constructing a Markov Chain such that the stationary distribution is the target distribution. In this case, the target distribution is the posterior distribution of the unknown model parameters that we want to estimate.</p>
<p id="1292" class="graf graf--p graf-after--p">Below is a screenshot from my code, where I used MH-MCMC to estimate the model parameters alpha, beta and sigma.</p>

<figure id="bb22" class="graf graf--figure graf-after--p">
<div class="aspectRatioPlaceholder is-locked">

[caption id="attachment_56" align="alignnone" width="866"]<a href="https://rhondenewint.files.wordpress.com/2019/01/mh_trace.png" target="_blank" rel="noopener"><img class="alignnone size-full wp-image-56" src="https://rhondenewint.files.wordpress.com/2019/01/mh_trace.png" alt="mh_trace" width="866" height="524" /></a> <a href="https://github.com/rhondene/Probablistic_Bayesian_Models/blob/master/Intro_to_MCMC_PyMC3.ipynb">Excerpt from my code: Assessing MCMC performance</a>[/caption]

</div>
</figure>
<div>
<h4 id="4fc4" class="graf graf--h4 graf-after--figure">from Thomas Wiecki’s blog <a class="markup--anchor markup--h4-anchor" href="http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/" target="_blank" rel="nofollow noopener" data-href="http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/">post</a> on MCMC</h4>
<p id="99e2" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">The basic idea is to sample from the posterior distribution by combining a “random search” (the Monte Carlo aspect) with a mechanism for intelligently “jumping” around, but in a manner that ultimately doesn’t depend on where we started from (the Markov Chain aspect). Hence Markov Chain Monte Carlo methods are memoryless searches performed with intelligent jumps.</em></p>
<p id="47d3" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">N.B</strong>: Prof. Matthew Heiner (UC Santa Cruz) gives an intuitive breakdown of the MCMC in his <em class="markup--em markup--p-em">Bayesian Statistics: Techniques and Models</em> course that you can audit for free on Coursera.</p>
<p id="d6a8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">No U-Turn Sampler (NUTS)</strong></p>
<p id="1bb7" class="graf graf--p graf-after--p">PyMC3’s most capable MCMC method is the No-U-Turn Sampler, an extension the Hamiltonian MCMC. The properties of NUTS enables faster convergence on high-dimensional target distributions especially those with many continuous variables, a situation where older MCMC algorithms work very slowly.</p>
<p id="1447" class="graf graf--p graf-after--p">Compare the NUTS-MCMC performance below with the Metropolis-Hastings.</p>

<figure id="6f34" class="graf graf--figure graf-after--p">
<div class="aspectRatioPlaceholder is-locked"><img class="alignnone size-full wp-image-57" src="https://rhondenewint.files.wordpress.com/2019/01/nuts_trace.png" alt="nuts_trace" width="892" height="421" /></div>
</figure>
<div>
<p id="b3d5" class="graf graf--p graf-after--figure">Even if you don’t know exactly what you should look out for when comparing these two methods, you can intuit that the NUTS plots <em class="markup--em markup--p-em">looks better </em>than the Metropolis-Hastings.</p>

<h3 id="471d" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">Conclusion:</strong></h3>
<p id="47d9" class="graf graf--p graf-after--h3">In a follow-up article I will explain in more detail how to evaluate the performance of a Markov Chains in order to find the best model parameters.</p>
<p id="1c8f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Resources</strong></p>
<p id="b924" class="graf graf--p graf-after--p">My primary learning resources for theory are:</p>

<ul class="postList">
	<li id="9a8c" class="graf graf--li graf-after--p"><em class="markup--em markup--li-em">Machine Learning- A Probabilistic Perspective</em> by Kevin Murphy (e-book,effective so far),</li>
	<li id="104f" class="graf graf--li graf-after--li"><em class="markup--em markup--li-em">Course Notes for Bayesian Models for Machine Learning</em> by John Paisley (Columbia University, google it)</li>
	<li id="6376" class="graf graf--li graf-after--li graf--trailing"><em class="markup--em markup--li-em">Information Theory, Inference and Learning Algorithms</em> by David Mackay (ebook, more intense read but worthwhile so far)</li>
</ul>
</div>
</div>
