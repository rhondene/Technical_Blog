# Data Preprocessing and Exploratory Data Analysis in Python - Beginner's Guide

Hello World!

In this article (my first!), I will walk you through a simple, yet generic workflow for data preprocessing and exploration using everyone's favourite data science programming language <i><b>python</b></i> in Jupyter notebook IDE on a biological dataset. But first, let's us talk about the what and why of data preprocessing. <i>The adage 'Garbage in, garbage out'</i> is what makes data preprocessing the first and most crucial quality control (and painstaking) step in building models and performing data analysis.

<b> Data Preprocessing </b> is the preparation and transformation of raw data into a meaningful format. In most cases you will be working with data that you personally did not generate, therefore you cannot guarantee the quality since most data were in some way generated by humans - humans will make mistakes. Therefore, data preprocessing is necessary because raw data is often noisy, with missing values, outliers or experimental artefacts, which distorts the kind of conclusions we can make from the data. <i> Always, always preprocess your data! </i>

There are 4 main components in the data preprocessing workflow:

- <b> Data Clean-up</b>: dealing with missing values , outliers or poorly formatted entries.
- <b>Data Integration</b>: combining data from multiple files or other sources in a meaningful way.
- <b> Data Transformation</b>: scaling, normalizing, aggregating and smoothing the data.
- <b>Data Reduction</b>: reducing the complexity or dimensionality of the data without compromising (too much) the integrity or intrinsic structure of the original data.

<img class="alignnone size-full wp-image-16" src="https://rhondenewint.files.wordpress.com/2018/11/data_preprocesssing.jpg" alt="data_preprocesssing" width="419" height="355" />

In this detailed <a href="https://github.com/rhondene/data_science_ML_lessons_biology"> coding tutorial </a>, I will walk you through a simple but common data preprocessing workflow using a flow cytometry dataset consisting of measurements of fluorescent labelled antibodies for blood cells. At the end, I also included principal componenet analysis and k-means clustering as an added bonus! I code in Python3 using the popular Jupyter notebook environment.Jupyter offers an interactive user-friendly environment and is widely used data analysis tool for reproducible research among scientists.  
<strong>Preview:Â </strong>

<img class="alignnone size-full wp-image-17" src="https://rhondenewint.files.wordpress.com/2018/11/img1.jpg" alt="Capture" width="712" height="504" />

<img class="alignnone size-full wp-image-20" src="https://rhondenewint.files.wordpress.com/2018/11/ig2.jpg" alt="i,g2" width="712" height="584" />

<img class="alignnone size-full wp-image-18" src="https://rhondenewint.files.wordpress.com/2018/11/capture2.jpg" alt="Capture2" width="821" height="449" />


If you are completely new to running python in jupyter notebook environment, please watch this short <a href="https://www.youtube.com/watch?v=dgjEUcccRwM">video</a> to get your system up and running.

Happy Learning

